{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "start = \"2008-01-01\"\n",
    "end = \"2025-01-01\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d39d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = yf.download(\"^GSPC\", start =start, end= end)\n",
    "vix = yf.download(\"^VIX\", start=start, end=end)\n",
    "skew = yf.download(\"^SKEW\", start=start, end=end)\n",
    "\n",
    "\n",
    "\n",
    "spx = index.add_prefix(\"SPX_\")\n",
    "vix   = vix.add_prefix(\"VIX_\")\n",
    "skew  = skew.add_prefix(\"SKEW_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spx.join(vix, how=\"inner\").join(skew, how=\"inner\")\n",
    "\n",
    "if isinstance(df.columns, pd.MultiIndex):\n",
    "    df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea80209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SPX_Return\"] = np.log(df[\"SPX_Close\"] / df[\"SPX_Close\"].shift(1))  # Log returns\n",
    "df[\"Abs_Return\"] = df[\"SPX_Return\"].abs()                               # Absolute returns\n",
    "df[\"RealizedVol_21d\"] = df[\"SPX_Return\"].rolling(21).std() * np.sqrt(252)  # 21-day annualized vol\n",
    "df[\"vol\"] = df[\"SPX_Return\"].rolling(5).std() * np.sqrt(252)            # 5-day annualized vol\n",
    "df[\"VIX_Change\"] = df[\"VIX_Close\"].pct_change()                         # VIX daily change\n",
    "df[\"IV_RV_Spread\"] = (df[\"VIX_Close\"] / 100) - df[\"RealizedVol_21d\"]    # Implied - Realized vol\n",
    "df[\"Vol_Ratio\"] = (df[\"VIX_Close\"] / 100) / df[\"RealizedVol_21d\"]       # IV/RV ratio\n",
    "df[\"SKEW_Change\"] = df[\"SKEW_Close\"].diff()                             # SKEW daily change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffd8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()  \n",
    "\n",
    "df = df[['SPX_Close','SPX_Open',\"SPX_High\",\"SPX_Low\",'SPX_Volume', \n",
    "        'VIX_Close','VIX_Open', 'SKEW_Close','SKEW_Open','SPX_Return', 'Abs_Return', 'RealizedVol_21d',\n",
    "        'IV_RV_Spread', 'VIX_Change', 'SKEW_Change', 'Vol_Ratio','vol']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = df.isnull().sum()\n",
    "print(missing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Daily_Range\"] = (df[\"SPX_High\"] - df[\"SPX_Low\"]) / df[\"SPX_Close\"]\n",
    "df[\"VIX_Spike\"] = (df[\"VIX_Close\"] - df[\"VIX_Close\"].rolling(5).mean()) / df[\"VIX_Close\"].rolling(5).mean()\n",
    "df[\"Vol_Acceleration\"] = df[\"RealizedVol_21d\"] - df[\"RealizedVol_21d\"].rolling(5).mean()\n",
    "df[\"Price_to_MA20\"] = df[\"SPX_Close\"] / df[\"SPX_Close\"].rolling(20).mean() - 1\n",
    "df[\"Return_Skew_10d\"] = df[\"SPX_Return\"].rolling(10).skew()\n",
    "df[\"SKEW_Deviation\"] = df[\"SKEW_Close\"] - df[\"SKEW_Close\"].rolling(10).mean()\n",
    "df[\"Volume_Spike\"] = df[\"SPX_Volume\"] / df[\"SPX_Volume\"].rolling(20).mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1988a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interest Rates\n",
    "df[\"US10Y\"] = yf.download(\"^TNX\", start=start, end=end)[\"Close\"]\n",
    "df[\"Yield_2Y\"] = yf.download(\"^IRX\", start=start, end=end)[\"Close\"]\n",
    "df[\"Yield_Curve\"] = df[\"US10Y\"] - df[\"Yield_2Y\"]  # 10Y-2Y spread\n",
    "\n",
    "# Dollar\n",
    "df[\"DXY\"] = yf.download(\"DX-Y.NYB\", start=start, end=end)[\"Close\"]\n",
    "df[\"DXY_Change\"] = df[\"DXY\"].pct_change()\n",
    "\n",
    "# Gold (safe haven)\n",
    "df[\"Gold\"] = yf.download(\"GC=F\", start=start, end=end)[\"Close\"]\n",
    "df[\"Gold_Return\"] = df[\"Gold\"].pct_change()\n",
    "\n",
    "# Credit Spreads\n",
    "df[\"HYG\"] = yf.download(\"HYG\", start=start, end=end)[\"Close\"]  # High Yield\n",
    "df[\"LQD\"] = yf.download(\"LQD\", start=start, end=end)[\"Close\"]  # Investment Grade\n",
    "df[\"HYG_Return\"] = df[\"HYG\"].pct_change()\n",
    "df[\"LQD_Return\"] = df[\"LQD\"].pct_change()\n",
    "df[\"Credit_Spread_Returns\"] = df[\"HYG_Return\"] - df[\"LQD_Return\"]  # Risky bonds - Safe bonds returns\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete list of features \n",
    "df_final = df[[\n",
    "        'SPX_Close',\n",
    "        'SPX_Return',\n",
    "        'RealizedVol_21d',\n",
    "        'VIX_Close',\n",
    "        'VIX_Change',\n",
    "        'IV_RV_Spread',\n",
    "        'Vol_Ratio',\n",
    "        'Vol_Acceleration',\n",
    "        'VIX_Spike',\n",
    "        'vol',\n",
    "\n",
    "        #SKEW\n",
    "        'SKEW_Close',\n",
    "        'SKEW_Change',\n",
    "        'SKEW_Deviation',\n",
    "\n",
    "        #Prix/Returns\n",
    "        'Abs_Return',\n",
    "        'Daily_Range',\n",
    "        'Price_to_MA20',\n",
    "        'Return_Skew_10d',\n",
    "\n",
    "        #Volume\n",
    "        'Volume_Spike',\n",
    "\n",
    "        #Interest rate\n",
    "        'Yield_Curve',  # 10Y-2Y spread (inversion = récession)\n",
    "\n",
    "        #Devises\n",
    "        'DXY_Change',  # Dollar Index\n",
    "\n",
    "        #Commo\n",
    "        'Gold_Return',\n",
    "\n",
    "        # Additionnal features\n",
    "        'HYG_Return',\n",
    "        'LQD_Return',\n",
    "        'Credit_Spread_Returns'\n",
    "\n",
    "    ]]\n",
    "\n",
    "df_final\n",
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# parametres \n",
    "lookback = 30  # Utiliser 30 jours passés\n",
    "forecast_horizon = 5  # Prédire 5 jours dans le futur\n",
    "start_date = '2008-01-01'\n",
    "split_date = '2019-12-31' # Séparation Train/Test avant la crise de la Covid-19\n",
    "\n",
    "# reminder of our features of xgb\n",
    "features1 = [\n",
    "    'SPX_Return', 'VIX_Close', 'SKEW_Close', 'RealizedVol_21d',\n",
    "    'IV_RV_Spread', 'Volume_Spike', 'Yield_Curve',\n",
    "    'Gold_Return', 'Credit_Spread_Returns'\n",
    "]\n",
    "\n",
    "#definition of the target \n",
    "target_feature = 'RealizedVol_21d'\n",
    "\n",
    "\n",
    "df_final['Future_Volatility'] = df_final[target_feature].shift(-forecast_horizon)\n",
    "df_final.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = df_final[features1].values\n",
    "y = df_final['Future_Volatility'].values\n",
    "\n",
    "#sequences creation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, labels, lookback):\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data[i-lookback:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled.flatten(), lookback)\n",
    "\n",
    "#train/test\n",
    "\n",
    "#we try to find the split date, 2019 in the data, if not found then keyerror and we split 80% of the data for the train, lstm needs time series\n",
    "try:\n",
    "    split_idx_data = df_final.index.get_loc(split_date)\n",
    "except KeyError:\n",
    "    split_idx_data = int(len(df_final) * 0.8)\n",
    "\n",
    "# index of separation must take into account the lookback\n",
    "split_idx_seq = split_idx_data - lookback\n",
    "\n",
    "if split_idx_seq < 0:\n",
    "    split_idx_seq = int(len(X_seq) * 0.8)\n",
    "\n",
    "X_train_lstm = X_seq[:split_idx_seq]\n",
    "y_train_lstm = y_seq[:split_idx_seq]\n",
    "X_test_lstm = X_seq[split_idx_seq:]\n",
    "y_test_lstm = y_seq[split_idx_seq:]\n",
    "\n",
    "#implementation of the model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(lookback, len(features1))),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_lstm, y_test_lstm),\n",
    "    verbose=0 # Mis à 0 pour la clarté de la réponse\n",
    ")\n",
    "\n",
    "#prediction\n",
    "y_pred_lstm = model.predict(X_test_lstm)\n",
    "predictions = scaler.inverse_transform(y_pred_lstm)\n",
    "y_test_real = scaler.inverse_transform(y_test_lstm.reshape(-1, 1))\n",
    "\n",
    "#visualisation\n",
    "\n",
    "dates_test_full = df_final.index[lookback:][split_idx_seq:]\n",
    "dates_test = dates_test_full[:len(y_test_real)] # S'assurer que l'index a la même taille que y_test_real\n",
    "\n",
    "# if the index is too short then the probleme is the initail indexation\n",
    "if len(dates_test) != len(y_test_real):\n",
    "    print(\" Erreur d'alignement: Index de {len(dates_test)} dates vs {len(y_test_real)} points. Vérifiez split_date.\")\n",
    "    dates_test = pd.to_datetime(np.arange(len(y_test_real))) # default index\n",
    "    \n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(dates_test, y_test_real, label=f\"reel volatility \", color='blue', linewidth=2)\n",
    "plt.plot(dates_test, predictions, label=f\"lstm predictions (5 days)\", color='red', linestyle='dashed', linewidth=1.5)\n",
    "\n",
    "plt.axvspan(pd.to_datetime('2020-02-20'), pd.to_datetime('2020-04-01'), color='gray', alpha=0.3, label='Crise COVID-19')\n",
    "\n",
    "plt.title(f\"volatility prediction using lstm\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Annualized volatility\", fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
